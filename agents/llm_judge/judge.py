from google import genai
import re

PROMPT = """You are a senior official in a tech company that is creating a multi-agent system to find the best bank accounts for the users. Your goal is to evaluate the response based on its adherence to the users input and the rules given to it in the prompt.

Your response should be in one of the following forms:

Response 1: "SATISFACTORY: <details of why it is good>"

Response 2: "UNSATISFACTORY: <details of why it should be redone>"

A satisfactory response would be one that follows the exact wording rules where necessary, calls the tools it has access to, and produces the correct output.

General Rules to follow:
- The agent can only make one tool call at a time. It is not allowed to call different tools.
- When calling tools, the agent does not have to specify keywords. Both f(x) and f(input=x) are acceptable.
- When asking a question, the agent must wait for the user to respond before it can continue.
- If a tool is unavailable, it should attempt to use the tool again.
- Agent asks question <Question>, user doesn't provide relevant response. The agent should ask the question again.

Examples:
- SavingsTriage() would be unsatisfactory, the agent has not followed the given syntax for that handoff
- tool1(x,y), tool2(a,b) would be unsatisfactory, the agent can only call 1 tool at a time
- search_tool(search="lorem ipsum...") and search_tool("lorem ipsum...") are both satisfactory calls since it doesn't have to give arguments



The following text will be the prompt followed by the LLM response:
"""


class LLMJudge:
    def __init__(self, model_name: str = "gemini-2.5-flash-lite"):
        """Initialize the agent

        Args:
            model_name (str, optional): Google gemini model to use. Defaults to "gemini-2.5-flash".
            main_prompt (str, optional): Prompt for the agent to use. Defaults to "".
            tools (list, optional): Which tools the agent has access to. Defaults to [].
        """
        # Initialize the agent with model, prompt, and tools
        self.model_name = model_name
        self.agent = genai.Client()
        self.main_prompt = PROMPT



    def get_response(self, prompt: str | None) -> str | None:
        """Get a response from the LLM

        Args:
            prompt (str): The prompt

        Returns:
            str | None: The response generated by the LLM
        """
        if prompt == None:
            return "No prompt provided"

        response = self.agent.models.generate_content(model=self.model_name, contents=prompt)
        return response.text

    def judger(self, prompt:str, response) -> str:

        inp = self.main_prompt + "\n" + prompt + "\nAGENT RESPONSE: " + response

        out = self.get_response(inp)

        if out == None:
            return "Error generating answer"
        return out
